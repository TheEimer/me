---
layout: distill
title: TempoRL - Learning When to Act
description: Getting the best out of RL by learning when to act.
date: 2022-05-27

authors:
  - name: Andr√© Biedenkapp
    affiliations:
      name: University of Freiburg
  - name: Raghu Rajan
    url: https://ml.informatik.uni-freiburg.de/profile/rajan/
    affiliations:
      name: University of Freiburg
  - name: Frank Hutter
    url: https://ml.informatik.uni-freiburg.de/profile/hutter/
    affiliations:
      name: University of Freiburg, BCAI
  - name: Marius Lindauer
    url: https://www.tnt.uni-hannover.de/staff/lindauer/
    affiliations:
      name: Leibniz University Hannover

bibliography: 2022-06-01-temporl.bib

py-ver: 2022.09.1

py-env:
 - numpy

toc:
  - name: Why Should RL Agents be More Proactive?
  - name: How to Train Proactive RL Agents
  - name: TempoRL
    subsections:
    - name: Tabular Agents
    - name: Deep RL Agents
  - name: Conclusion
  - name: References

---

**Note: this is a test**
